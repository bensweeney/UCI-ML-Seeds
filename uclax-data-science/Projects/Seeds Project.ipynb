{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEEDS PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bensweeney/uclax-data-science/Projects'"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Perimeter</th>\n",
       "      <th>Compactness</th>\n",
       "      <th>Length_of_Kernel</th>\n",
       "      <th>Width_of_Kernel</th>\n",
       "      <th>Asymmetry_Coefficient</th>\n",
       "      <th>Length_of_Kernel_Groove</th>\n",
       "      <th>Target</th>\n",
       "      <th>Names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.84</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>5.763</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.2210</td>\n",
       "      <td>5.220</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.88</td>\n",
       "      <td>14.57</td>\n",
       "      <td>0.8811</td>\n",
       "      <td>5.554</td>\n",
       "      <td>3.333</td>\n",
       "      <td>1.0180</td>\n",
       "      <td>4.956</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.29</td>\n",
       "      <td>14.09</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>5.291</td>\n",
       "      <td>3.337</td>\n",
       "      <td>2.6990</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.84</td>\n",
       "      <td>13.94</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.324</td>\n",
       "      <td>3.379</td>\n",
       "      <td>2.2590</td>\n",
       "      <td>4.805</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.14</td>\n",
       "      <td>14.99</td>\n",
       "      <td>0.9034</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.562</td>\n",
       "      <td>1.3550</td>\n",
       "      <td>5.175</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.38</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>5.386</td>\n",
       "      <td>3.312</td>\n",
       "      <td>2.4620</td>\n",
       "      <td>4.956</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.69</td>\n",
       "      <td>14.49</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>5.563</td>\n",
       "      <td>3.259</td>\n",
       "      <td>3.5860</td>\n",
       "      <td>5.219</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.10</td>\n",
       "      <td>0.8911</td>\n",
       "      <td>5.420</td>\n",
       "      <td>3.302</td>\n",
       "      <td>2.7000</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.63</td>\n",
       "      <td>15.46</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>6.053</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.0400</td>\n",
       "      <td>5.877</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.44</td>\n",
       "      <td>15.25</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.884</td>\n",
       "      <td>3.505</td>\n",
       "      <td>1.9690</td>\n",
       "      <td>5.533</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15.26</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.8696</td>\n",
       "      <td>5.714</td>\n",
       "      <td>3.242</td>\n",
       "      <td>4.5430</td>\n",
       "      <td>5.314</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.03</td>\n",
       "      <td>14.16</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>5.438</td>\n",
       "      <td>3.201</td>\n",
       "      <td>1.7170</td>\n",
       "      <td>5.001</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.89</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>5.439</td>\n",
       "      <td>3.199</td>\n",
       "      <td>3.9860</td>\n",
       "      <td>4.738</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.78</td>\n",
       "      <td>14.06</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>5.479</td>\n",
       "      <td>3.156</td>\n",
       "      <td>3.1360</td>\n",
       "      <td>4.872</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.74</td>\n",
       "      <td>14.05</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>5.482</td>\n",
       "      <td>3.114</td>\n",
       "      <td>2.9320</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.59</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>5.351</td>\n",
       "      <td>3.333</td>\n",
       "      <td>4.1850</td>\n",
       "      <td>4.781</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>13.99</td>\n",
       "      <td>13.83</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>5.119</td>\n",
       "      <td>3.383</td>\n",
       "      <td>5.2340</td>\n",
       "      <td>4.781</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15.69</td>\n",
       "      <td>14.75</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>5.527</td>\n",
       "      <td>3.514</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>5.046</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.70</td>\n",
       "      <td>14.21</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>5.205</td>\n",
       "      <td>3.466</td>\n",
       "      <td>1.7670</td>\n",
       "      <td>4.649</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>12.72</td>\n",
       "      <td>13.57</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>5.226</td>\n",
       "      <td>3.049</td>\n",
       "      <td>4.1020</td>\n",
       "      <td>4.914</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.16</td>\n",
       "      <td>14.40</td>\n",
       "      <td>0.8584</td>\n",
       "      <td>5.658</td>\n",
       "      <td>3.129</td>\n",
       "      <td>3.0720</td>\n",
       "      <td>5.176</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.26</td>\n",
       "      <td>0.8722</td>\n",
       "      <td>5.520</td>\n",
       "      <td>3.168</td>\n",
       "      <td>2.6880</td>\n",
       "      <td>5.219</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>15.88</td>\n",
       "      <td>14.90</td>\n",
       "      <td>0.8988</td>\n",
       "      <td>5.618</td>\n",
       "      <td>3.507</td>\n",
       "      <td>0.7651</td>\n",
       "      <td>5.091</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>12.08</td>\n",
       "      <td>13.23</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>5.099</td>\n",
       "      <td>2.936</td>\n",
       "      <td>1.4150</td>\n",
       "      <td>4.961</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>15.01</td>\n",
       "      <td>14.76</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>5.789</td>\n",
       "      <td>3.245</td>\n",
       "      <td>1.7910</td>\n",
       "      <td>5.001</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>16.19</td>\n",
       "      <td>15.16</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.833</td>\n",
       "      <td>3.421</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>5.307</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>13.02</td>\n",
       "      <td>13.76</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>5.395</td>\n",
       "      <td>3.026</td>\n",
       "      <td>3.3730</td>\n",
       "      <td>4.825</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>12.74</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>5.395</td>\n",
       "      <td>2.956</td>\n",
       "      <td>2.5040</td>\n",
       "      <td>4.869</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>14.11</td>\n",
       "      <td>14.18</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>5.541</td>\n",
       "      <td>3.221</td>\n",
       "      <td>2.7540</td>\n",
       "      <td>5.038</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>13.45</td>\n",
       "      <td>14.02</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>5.516</td>\n",
       "      <td>3.065</td>\n",
       "      <td>3.5310</td>\n",
       "      <td>5.097</td>\n",
       "      <td>0</td>\n",
       "      <td>Kama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>11.41</td>\n",
       "      <td>12.95</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>5.090</td>\n",
       "      <td>2.775</td>\n",
       "      <td>4.9570</td>\n",
       "      <td>4.825</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>12.46</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8706</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.017</td>\n",
       "      <td>4.9870</td>\n",
       "      <td>5.147</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.36</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>5.240</td>\n",
       "      <td>2.909</td>\n",
       "      <td>4.8570</td>\n",
       "      <td>5.158</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>11.65</td>\n",
       "      <td>13.07</td>\n",
       "      <td>0.8575</td>\n",
       "      <td>5.108</td>\n",
       "      <td>2.850</td>\n",
       "      <td>5.2090</td>\n",
       "      <td>5.135</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>12.89</td>\n",
       "      <td>13.77</td>\n",
       "      <td>0.8541</td>\n",
       "      <td>5.495</td>\n",
       "      <td>3.026</td>\n",
       "      <td>6.1850</td>\n",
       "      <td>5.316</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>11.56</td>\n",
       "      <td>13.31</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.363</td>\n",
       "      <td>2.683</td>\n",
       "      <td>4.0620</td>\n",
       "      <td>5.182</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>11.81</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.8198</td>\n",
       "      <td>5.413</td>\n",
       "      <td>2.716</td>\n",
       "      <td>4.8980</td>\n",
       "      <td>5.352</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>10.91</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8372</td>\n",
       "      <td>5.088</td>\n",
       "      <td>2.675</td>\n",
       "      <td>4.1790</td>\n",
       "      <td>4.956</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.82</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2.821</td>\n",
       "      <td>7.5240</td>\n",
       "      <td>4.957</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>10.59</td>\n",
       "      <td>12.41</td>\n",
       "      <td>0.8648</td>\n",
       "      <td>4.899</td>\n",
       "      <td>2.787</td>\n",
       "      <td>4.9750</td>\n",
       "      <td>4.794</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>10.93</td>\n",
       "      <td>12.80</td>\n",
       "      <td>0.8390</td>\n",
       "      <td>5.046</td>\n",
       "      <td>2.717</td>\n",
       "      <td>5.3980</td>\n",
       "      <td>5.045</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>11.27</td>\n",
       "      <td>12.86</td>\n",
       "      <td>0.8563</td>\n",
       "      <td>5.091</td>\n",
       "      <td>2.804</td>\n",
       "      <td>3.9850</td>\n",
       "      <td>5.001</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>11.87</td>\n",
       "      <td>13.02</td>\n",
       "      <td>0.8795</td>\n",
       "      <td>5.132</td>\n",
       "      <td>2.953</td>\n",
       "      <td>3.5970</td>\n",
       "      <td>5.132</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>10.82</td>\n",
       "      <td>12.83</td>\n",
       "      <td>0.8256</td>\n",
       "      <td>5.180</td>\n",
       "      <td>2.630</td>\n",
       "      <td>4.8530</td>\n",
       "      <td>5.089</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>12.11</td>\n",
       "      <td>13.27</td>\n",
       "      <td>0.8639</td>\n",
       "      <td>5.236</td>\n",
       "      <td>2.975</td>\n",
       "      <td>4.1320</td>\n",
       "      <td>5.012</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>12.80</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8860</td>\n",
       "      <td>5.160</td>\n",
       "      <td>3.126</td>\n",
       "      <td>4.8730</td>\n",
       "      <td>4.914</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>12.79</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.8786</td>\n",
       "      <td>5.224</td>\n",
       "      <td>3.054</td>\n",
       "      <td>5.4830</td>\n",
       "      <td>4.958</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>13.37</td>\n",
       "      <td>13.78</td>\n",
       "      <td>0.8849</td>\n",
       "      <td>5.320</td>\n",
       "      <td>3.128</td>\n",
       "      <td>4.6700</td>\n",
       "      <td>5.091</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>12.62</td>\n",
       "      <td>13.67</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>5.410</td>\n",
       "      <td>2.911</td>\n",
       "      <td>3.3060</td>\n",
       "      <td>5.231</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>12.76</td>\n",
       "      <td>13.38</td>\n",
       "      <td>0.8964</td>\n",
       "      <td>5.073</td>\n",
       "      <td>3.155</td>\n",
       "      <td>2.8280</td>\n",
       "      <td>4.830</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>12.38</td>\n",
       "      <td>13.44</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>5.219</td>\n",
       "      <td>2.989</td>\n",
       "      <td>5.4720</td>\n",
       "      <td>5.045</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>12.67</td>\n",
       "      <td>13.32</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>4.984</td>\n",
       "      <td>3.135</td>\n",
       "      <td>2.3000</td>\n",
       "      <td>4.745</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>11.18</td>\n",
       "      <td>12.72</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>5.009</td>\n",
       "      <td>2.810</td>\n",
       "      <td>4.0510</td>\n",
       "      <td>4.828</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>12.70</td>\n",
       "      <td>13.41</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>5.183</td>\n",
       "      <td>3.091</td>\n",
       "      <td>8.4560</td>\n",
       "      <td>5.000</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>12.37</td>\n",
       "      <td>13.47</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>5.204</td>\n",
       "      <td>2.960</td>\n",
       "      <td>3.9190</td>\n",
       "      <td>5.001</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>12.19</td>\n",
       "      <td>13.20</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>5.137</td>\n",
       "      <td>2.981</td>\n",
       "      <td>3.6310</td>\n",
       "      <td>4.870</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>11.23</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.8511</td>\n",
       "      <td>5.140</td>\n",
       "      <td>2.795</td>\n",
       "      <td>4.3250</td>\n",
       "      <td>5.003</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>13.20</td>\n",
       "      <td>13.66</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>5.236</td>\n",
       "      <td>3.232</td>\n",
       "      <td>8.3150</td>\n",
       "      <td>5.056</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>11.84</td>\n",
       "      <td>13.21</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>5.175</td>\n",
       "      <td>2.836</td>\n",
       "      <td>3.5980</td>\n",
       "      <td>5.044</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>12.30</td>\n",
       "      <td>13.34</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>5.243</td>\n",
       "      <td>2.974</td>\n",
       "      <td>5.6370</td>\n",
       "      <td>5.063</td>\n",
       "      <td>2</td>\n",
       "      <td>Canadian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Area  Perimeter  Compactness  Length_of_Kernel  Width_of_Kernel  \\\n",
       "0    15.26      14.84       0.8710             5.763            3.312   \n",
       "1    14.88      14.57       0.8811             5.554            3.333   \n",
       "2    14.29      14.09       0.9050             5.291            3.337   \n",
       "3    13.84      13.94       0.8955             5.324            3.379   \n",
       "4    16.14      14.99       0.9034             5.658            3.562   \n",
       "5    14.38      14.21       0.8951             5.386            3.312   \n",
       "6    14.69      14.49       0.8799             5.563            3.259   \n",
       "7    14.11      14.10       0.8911             5.420            3.302   \n",
       "8    16.63      15.46       0.8747             6.053            3.465   \n",
       "9    16.44      15.25       0.8880             5.884            3.505   \n",
       "10   15.26      14.85       0.8696             5.714            3.242   \n",
       "11   14.03      14.16       0.8796             5.438            3.201   \n",
       "12   13.89      14.02       0.8880             5.439            3.199   \n",
       "13   13.78      14.06       0.8759             5.479            3.156   \n",
       "14   13.74      14.05       0.8744             5.482            3.114   \n",
       "15   14.59      14.28       0.8993             5.351            3.333   \n",
       "16   13.99      13.83       0.9183             5.119            3.383   \n",
       "17   15.69      14.75       0.9058             5.527            3.514   \n",
       "18   14.70      14.21       0.9153             5.205            3.466   \n",
       "19   12.72      13.57       0.8686             5.226            3.049   \n",
       "20   14.16      14.40       0.8584             5.658            3.129   \n",
       "21   14.11      14.26       0.8722             5.520            3.168   \n",
       "22   15.88      14.90       0.8988             5.618            3.507   \n",
       "23   12.08      13.23       0.8664             5.099            2.936   \n",
       "24   15.01      14.76       0.8657             5.789            3.245   \n",
       "25   16.19      15.16       0.8849             5.833            3.421   \n",
       "26   13.02      13.76       0.8641             5.395            3.026   \n",
       "27   12.74      13.67       0.8564             5.395            2.956   \n",
       "28   14.11      14.18       0.8820             5.541            3.221   \n",
       "29   13.45      14.02       0.8604             5.516            3.065   \n",
       "..     ...        ...          ...               ...              ...   \n",
       "180  11.41      12.95       0.8560             5.090            2.775   \n",
       "181  12.46      13.41       0.8706             5.236            3.017   \n",
       "182  12.19      13.36       0.8579             5.240            2.909   \n",
       "183  11.65      13.07       0.8575             5.108            2.850   \n",
       "184  12.89      13.77       0.8541             5.495            3.026   \n",
       "185  11.56      13.31       0.8198             5.363            2.683   \n",
       "186  11.81      13.45       0.8198             5.413            2.716   \n",
       "187  10.91      12.80       0.8372             5.088            2.675   \n",
       "188  11.23      12.82       0.8594             5.089            2.821   \n",
       "189  10.59      12.41       0.8648             4.899            2.787   \n",
       "190  10.93      12.80       0.8390             5.046            2.717   \n",
       "191  11.27      12.86       0.8563             5.091            2.804   \n",
       "192  11.87      13.02       0.8795             5.132            2.953   \n",
       "193  10.82      12.83       0.8256             5.180            2.630   \n",
       "194  12.11      13.27       0.8639             5.236            2.975   \n",
       "195  12.80      13.47       0.8860             5.160            3.126   \n",
       "196  12.79      13.53       0.8786             5.224            3.054   \n",
       "197  13.37      13.78       0.8849             5.320            3.128   \n",
       "198  12.62      13.67       0.8481             5.410            2.911   \n",
       "199  12.76      13.38       0.8964             5.073            3.155   \n",
       "200  12.38      13.44       0.8609             5.219            2.989   \n",
       "201  12.67      13.32       0.8977             4.984            3.135   \n",
       "202  11.18      12.72       0.8680             5.009            2.810   \n",
       "203  12.70      13.41       0.8874             5.183            3.091   \n",
       "204  12.37      13.47       0.8567             5.204            2.960   \n",
       "205  12.19      13.20       0.8783             5.137            2.981   \n",
       "206  11.23      12.88       0.8511             5.140            2.795   \n",
       "207  13.20      13.66       0.8883             5.236            3.232   \n",
       "208  11.84      13.21       0.8521             5.175            2.836   \n",
       "209  12.30      13.34       0.8684             5.243            2.974   \n",
       "\n",
       "     Asymmetry_Coefficient  Length_of_Kernel_Groove  Target     Names  \n",
       "0                   2.2210                    5.220       0      Kama  \n",
       "1                   1.0180                    4.956       0      Kama  \n",
       "2                   2.6990                    4.825       0      Kama  \n",
       "3                   2.2590                    4.805       0      Kama  \n",
       "4                   1.3550                    5.175       0      Kama  \n",
       "5                   2.4620                    4.956       0      Kama  \n",
       "6                   3.5860                    5.219       0      Kama  \n",
       "7                   2.7000                    5.000       0      Kama  \n",
       "8                   2.0400                    5.877       0      Kama  \n",
       "9                   1.9690                    5.533       0      Kama  \n",
       "10                  4.5430                    5.314       0      Kama  \n",
       "11                  1.7170                    5.001       0      Kama  \n",
       "12                  3.9860                    4.738       0      Kama  \n",
       "13                  3.1360                    4.872       0      Kama  \n",
       "14                  2.9320                    4.825       0      Kama  \n",
       "15                  4.1850                    4.781       0      Kama  \n",
       "16                  5.2340                    4.781       0      Kama  \n",
       "17                  1.5990                    5.046       0      Kama  \n",
       "18                  1.7670                    4.649       0      Kama  \n",
       "19                  4.1020                    4.914       0      Kama  \n",
       "20                  3.0720                    5.176       0      Kama  \n",
       "21                  2.6880                    5.219       0      Kama  \n",
       "22                  0.7651                    5.091       0      Kama  \n",
       "23                  1.4150                    4.961       0      Kama  \n",
       "24                  1.7910                    5.001       0      Kama  \n",
       "25                  0.9030                    5.307       0      Kama  \n",
       "26                  3.3730                    4.825       0      Kama  \n",
       "27                  2.5040                    4.869       0      Kama  \n",
       "28                  2.7540                    5.038       0      Kama  \n",
       "29                  3.5310                    5.097       0      Kama  \n",
       "..                     ...                      ...     ...       ...  \n",
       "180                 4.9570                    4.825       2  Canadian  \n",
       "181                 4.9870                    5.147       2  Canadian  \n",
       "182                 4.8570                    5.158       2  Canadian  \n",
       "183                 5.2090                    5.135       2  Canadian  \n",
       "184                 6.1850                    5.316       2  Canadian  \n",
       "185                 4.0620                    5.182       2  Canadian  \n",
       "186                 4.8980                    5.352       2  Canadian  \n",
       "187                 4.1790                    4.956       2  Canadian  \n",
       "188                 7.5240                    4.957       2  Canadian  \n",
       "189                 4.9750                    4.794       2  Canadian  \n",
       "190                 5.3980                    5.045       2  Canadian  \n",
       "191                 3.9850                    5.001       2  Canadian  \n",
       "192                 3.5970                    5.132       2  Canadian  \n",
       "193                 4.8530                    5.089       2  Canadian  \n",
       "194                 4.1320                    5.012       2  Canadian  \n",
       "195                 4.8730                    4.914       2  Canadian  \n",
       "196                 5.4830                    4.958       2  Canadian  \n",
       "197                 4.6700                    5.091       2  Canadian  \n",
       "198                 3.3060                    5.231       2  Canadian  \n",
       "199                 2.8280                    4.830       2  Canadian  \n",
       "200                 5.4720                    5.045       2  Canadian  \n",
       "201                 2.3000                    4.745       2  Canadian  \n",
       "202                 4.0510                    4.828       2  Canadian  \n",
       "203                 8.4560                    5.000       2  Canadian  \n",
       "204                 3.9190                    5.001       2  Canadian  \n",
       "205                 3.6310                    4.870       2  Canadian  \n",
       "206                 4.3250                    5.003       2  Canadian  \n",
       "207                 8.3150                    5.056       2  Canadian  \n",
       "208                 3.5980                    5.044       2  Canadian  \n",
       "209                 5.6370                    5.063       2  Canadian  \n",
       "\n",
       "[210 rows x 9 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from time import time\n",
    "from bic import BIC\n",
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from patsy import dmatrices\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.dummy import DummyClassifier\n",
    "import scipy.stats as ss\n",
    "from sklearn.metrics import recall_score  \n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "features = ['Area','Perimeter','Compactness','Length_of_Kernel','Width_of_Kernel','Asymmetry_Coefficient','Length_of_Kernel_Groove','Target']\n",
    "SEEDS_DATA_URL = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00236/seeds_dataset.txt'\n",
    "seeds_df = pd.read_csv(SEEDS_DATA_URL, sep=\"\\s+\", header= None)\n",
    "seeds_df.columns = features\n",
    "\n",
    "\n",
    "wheat_seeds = np.array(['Kama','Rosa','Canadian'])\n",
    "\n",
    "seeds_df[\"Target\"]= seeds_df[\"Target\"]-1\n",
    "\n",
    "seeds_df[\"Names\"] = [wheat_seeds[i] for i in seeds_df[\"Target\"]]\n",
    "\n",
    "seeds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seeds_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data (pairplots)\n",
    "\n",
    "# plt.figure(1, (10,10))\n",
    "# sns.pairplot(seeds_df, size=2, aspect=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulize the data (bar graphs)\n",
    "\n",
    "# _, ax = plt.subplots(1,4, figsize=(20,6))\n",
    "\n",
    "# for i in range(4):\n",
    "#     for seeds_class in seeds_df.target.unique():\n",
    "#         plotting_df = seeds_df[seeds_df.target == iris_class ]\n",
    "#         sns.distplot(plotting_df[features[i]], ax=ax[i], label=seeds_class)\n",
    "#         ax[i].legend()\n",
    "\n",
    "# sns.countplot(y=\"seeds_df\", data=seeds_df)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "\n",
    "targetTTS, featuresTTS = dmatrices(\"Target ~ Area\", seeds_df)\n",
    "\n",
    "(features_train,\n",
    " features_test,\n",
    " target_train,\n",
    " target_test) = train_test_split(featuresTTS, targetTTS, random_state=42) \n",
    "\n",
    "linear_regression_model = LinearRegression(fit_intercept=False)\n",
    "\n",
    "linear_regression_model.fit(features_train, target_train)\n",
    "\n",
    "petal_width_prediction_1_var = (linear_regression_model\n",
    "                                .predict(features_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fa68403c128>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1, (20,5))\n",
    "\n",
    "plt.scatter(features_test[:, 1], target_test, \n",
    "            marker='o', color='blue', alpha=0.5, \n",
    "            label='actual test values')\n",
    "plt.scatter(features_test[:, 1], petal_width_prediction_1_var,\n",
    "            marker='x', color='red', alpha=0.5, \n",
    "            label='predicted test values - 1 variable')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification (BIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BIC(features, target, model):\n",
    "    model.fit(features, target)\n",
    "    prediction = model.predict_proba(features)\n",
    "    n = len(target)\n",
    "    p = features.shape[1] #len(target.keys()) #\n",
    "    complexity = math.log(n)*(p+1)\n",
    "    likelyhood = -2*log_loss(target, prediction)\n",
    "    return complexity - likelyhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.6729747225\n",
      "43.3371999919\n",
      "43.2717473211\n",
      "43.2791965365\n",
      "43.2785888047\n",
      "43.3804378115\n",
      "43.445939933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#BIC Round 1\n",
    "\n",
    "target1_1, features1_1 = dmatrices(\"Target ~ 1 + Perimeter + Compactness + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_2, features1_2 = dmatrices(\"Target ~ 1 + Area + Compactness + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_3, features1_3 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_4, features1_4 = dmatrices(\"Target ~ 1 + Area + Perimeter + Compactness + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_5, features1_5 = dmatrices(\"Target ~ 1 + Area + Perimeter + Compactness + Length_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_6, features1_6 = dmatrices(\"Target ~ 1 + Area + Perimeter + Compactness + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "target1_7, features1_7 = dmatrices(\"Target ~ 1 + Area + Perimeter + Compactness + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient\", seeds_df)\n",
    "\n",
    "lr_seeds1_1 = LogisticRegression()\n",
    "lr_seeds1_2 = LogisticRegression()\n",
    "lr_seeds1_3 = LogisticRegression()\n",
    "lr_seeds1_4 = LogisticRegression()\n",
    "lr_seeds1_5 = LogisticRegression()\n",
    "lr_seeds1_6 = LogisticRegression()\n",
    "lr_seeds1_7 = LogisticRegression()\n",
    "\n",
    "BIC1_1 = BIC(features1_1, target1_1, lr_seeds1_1)\n",
    "print(BIC1_1)\n",
    "BIC1_2 = BIC(features1_2, target1_2, lr_seeds1_2)\n",
    "print(BIC1_2)\n",
    "BIC1_3 = BIC(features1_3, target1_3, lr_seeds1_3)\n",
    "print(BIC1_3)\n",
    "BIC1_4 = BIC(features1_4, target1_4, lr_seeds1_4)\n",
    "print(BIC1_4)\n",
    "BIC1_5 = BIC(features1_5, target1_5, lr_seeds1_5)\n",
    "print(BIC1_5)\n",
    "BIC1_6 = BIC(features1_6, target1_6, lr_seeds1_6)\n",
    "print(BIC1_6)\n",
    "BIC1_7 = BIC(features1_7, target1_7, lr_seeds1_7)\n",
    "print(BIC1_7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.366049682\n",
      "37.9966204582\n",
      "37.9334839964\n",
      "37.9334450434\n",
      "38.0346356199\n",
      "38.101351212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# BIC Round 2 (Remove Compactness)\n",
    "\n",
    "target2_1, features2_1 = dmatrices(\"Target ~ 1 + Perimeter + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target2_2, features2_2 = dmatrices(\"Target ~ 1 + Area + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target2_3, features2_3 = dmatrices(\"Target ~ 1 + Area + Perimeter + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target2_4, features2_4 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target2_5, features2_5 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "target2_6, features2_6 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel + Width_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient\", seeds_df)\n",
    "\n",
    "lr_seeds2_1 = LogisticRegression()\n",
    "lr_seeds2_2 = LogisticRegression()\n",
    "lr_seeds2_3 = LogisticRegression()\n",
    "lr_seeds2_4 = LogisticRegression()\n",
    "lr_seeds2_5 = LogisticRegression()\n",
    "lr_seeds2_6 = LogisticRegression()\n",
    "\n",
    "\n",
    "BIC2_1 = BIC(features2_1, target2_1, lr_seeds2_1)\n",
    "print(BIC2_1)\n",
    "BIC2_2 = BIC(features2_2, target2_2, lr_seeds2_2)\n",
    "print(BIC2_2)\n",
    "BIC2_3 = BIC(features2_3, target2_3, lr_seeds2_3)\n",
    "print(BIC2_3)\n",
    "BIC2_4 = BIC(features2_4, target2_4, lr_seeds2_4)\n",
    "print(BIC2_4)\n",
    "BIC2_5 = BIC(features2_5, target2_5, lr_seeds2_5)\n",
    "print(BIC2_5)\n",
    "BIC2_6 = BIC(features2_6, target2_6, lr_seeds2_6)\n",
    "print(BIC2_6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.0406109322\n",
      "32.7007824596\n",
      "32.594302053\n",
      "37.9334450434\n",
      "32.6939102493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# BIC Round 3 (Remove Compactness & Width of Kernel)\n",
    "\n",
    "target3_1, features3_1 = dmatrices(\"Target ~ 1 + Perimeter + Length_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target3_2, features3_2 = dmatrices(\"Target ~ 1 + Area + Length_of_Kernel  \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target3_3, features3_3 = dmatrices(\"Target ~ 1 + Area + Perimeter \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target3_4, features3_4 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target3_5, features3_5 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "\n",
    "lr_seeds3_1 = LogisticRegression()\n",
    "lr_seeds3_2 = LogisticRegression()\n",
    "lr_seeds3_3 = LogisticRegression()\n",
    "lr_seeds3_4 = LogisticRegression()\n",
    "lr_seeds3_5 = LogisticRegression()\n",
    "\n",
    "\n",
    "BIC3_1 = BIC(features3_1, target3_1, lr_seeds3_1)\n",
    "print(BIC3_1)\n",
    "BIC3_2 = BIC(features3_2, target3_2, lr_seeds3_2)\n",
    "print(BIC3_2)\n",
    "BIC3_3 = BIC(features3_3, target3_3, lr_seeds3_3)\n",
    "print(BIC3_3)\n",
    "BIC3_4 = BIC(features3_4, target3_4, lr_seeds3_4)\n",
    "print(BIC3_4)\n",
    "BIC3_5 = BIC(features3_5, target3_5, lr_seeds3_5)\n",
    "print(BIC3_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.759776583\n",
      "27.5509238393\n",
      "27.3570534074\n",
      "32.7868913354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# BIC Round 4 (Remove Compactness & Width of Kernel & Length of Kernel)\n",
    "\n",
    "target4_1, features4_1 = dmatrices(\"Target ~ 1 + Perimeter \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target4_2, features4_2 = dmatrices(\"Target ~ 1 + Area  \\\n",
    "                                        + Asymmetry_Coefficient + Length_of_Kernel_Groove\", seeds_df)\n",
    "target4_3, features4_3 = dmatrices(\"Target ~ 1 + Area + Perimeter \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "target4_4, features4_4 = dmatrices(\"Target ~ 1 + Area + Perimeter + Length_of_Kernel \\\n",
    "                                        + Asymmetry_Coefficient\", seeds_df)\n",
    "\n",
    "lr_seeds4_1 = LogisticRegression()\n",
    "lr_seeds4_2 = LogisticRegression()\n",
    "lr_seeds4_3 = LogisticRegression()\n",
    "lr_seeds4_4 = LogisticRegression()\n",
    "\n",
    "BIC4_1 = BIC(features4_1, target4_1, lr_seeds4_1)\n",
    "print(BIC4_1)\n",
    "BIC4_2 = BIC(features4_2, target4_2, lr_seeds4_2)\n",
    "print(BIC4_2)\n",
    "BIC4_3 = BIC(features4_3, target4_3, lr_seeds4_3)\n",
    "print(BIC4_3)\n",
    "BIC4_4 = BIC(features4_4, target4_4, lr_seeds4_4)\n",
    "print(BIC4_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.5536734039\n",
      "22.3225079558\n",
      "22.3321458648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# BIC Round 5 (Remove Compactness & Width of Kernel & Length of Kernel & Assymmetry Coefficient)\n",
    "\n",
    "target5_1, features5_1 = dmatrices(\"Target ~ 1 + Perimeter \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "target5_2, features5_2 = dmatrices(\"Target ~ 1 + Area  \\\n",
    "                                        + Length_of_Kernel_Groove\", seeds_df)\n",
    "target5_3, features5_3 = dmatrices(\"Target ~ 1 + Area + Perimeter\", seeds_df)\n",
    "\n",
    "lr_seeds5_1 = LogisticRegression()\n",
    "lr_seeds5_2 = LogisticRegression()\n",
    "lr_seeds5_3 = LogisticRegression()\n",
    "\n",
    "\n",
    "BIC5_1 = BIC(features5_1, target5_1, lr_seeds5_1)\n",
    "print(BIC5_1)\n",
    "BIC5_2 = BIC(features5_2, target5_2, lr_seeds5_2)\n",
    "print(BIC5_2)\n",
    "BIC5_3 = BIC(features5_3, target5_3, lr_seeds5_3)\n",
    "print(BIC5_3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.6799306502\n",
      "17.319382043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/utils/validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# BIC Round 6 (Remove Compactness & Width of Kernel & Length of Kernel & Assymmetry Coefficient & Length of Kernel Groove)\n",
    "\n",
    "target6_1, features6_1 = dmatrices(\"Target ~ 1 + Perimeter\", seeds_df)\n",
    "target6_2, features6_2 = dmatrices(\"Target ~ 1 + Area \", seeds_df)\n",
    "\n",
    "lr_seeds6_1 = LogisticRegression()\n",
    "lr_seeds6_2 = LogisticRegression()\n",
    "\n",
    "BIC6_1 = BIC(features6_1, target6_1, lr_seeds6_1)\n",
    "print(BIC6_1)\n",
    "BIC6_2 = BIC(features6_2, target6_2, lr_seeds6_2)\n",
    "print(BIC6_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FROM BIC WE SEE THAT THE CLASSIFICATION SHOULD BE DEFINED USING AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_time(model, data):\n",
    "    start = time()\n",
    "    model = model.fit(data)\n",
    "    end = time() - start\n",
    "    return {'fit_time' : end, 'model' : model}\n",
    "\n",
    "def process_results(results_list, data):\n",
    "    df = pd.DataFrame(results_list)\n",
    "    df['k'] = df.model.apply(lambda x: x.n_clusters)\n",
    "    df['bic'] = df.model.apply(lambda x: BIC(x, data))\n",
    "    df['sil_sc'] = df.model.apply(lambda x: silhouette_score(data, x.labels_))\n",
    "    df.set_index('k', inplace=True)\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
